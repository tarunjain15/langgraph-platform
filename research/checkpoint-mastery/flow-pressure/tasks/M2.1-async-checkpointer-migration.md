```yaml
task_id: M2.1
phase: M2
type: Integration
status: complete
created: 2025-11-17
completed: 2025-11-18
```

# Task 2.1: [Integration] Async Checkpointer Migration

## The Constraint

**Before:** Synchronous blocking I/O - concurrent invocations cause "database locked" errors
**After:** Async non-blocking I/O - 10+ concurrent invocations succeed without locks

---

## The Witness

**Observable Truth:** 10 concurrent `graph.ainvoke()` calls complete successfully with zero "database locked" errors

**Why This Witness:**
- Concurrent async execution without locks is **impossible** with sync SqliteSaver
- 10+ simultaneous invocations can ONLY succeed with AsyncSqliteSaver's connection pooling
- This removes the blocking I/O constraint that prevented production concurrency
- The witness is **zero lock errors** under concurrent load - if it exists, async migration succeeded

---

## Acceptance Criteria

**Must Verify:**
- [ ] `AsyncSqliteSaver` replaces `SqliteSaver` in all graph compilations
- [ ] Graph compilation uses `async with AsyncSqliteSaver.from_conn_string()` pattern
- [ ] All graph invocations use `await graph.ainvoke()` (not `.invoke()`)
- [ ] 10+ concurrent async invocations complete successfully
- [ ] Zero "database locked" errors in logs
- [ ] All async/await patterns work correctly (no deadlocks)
- [ ] M1 emergent features still work (Session Memory, Time Travel, HITL, Fault Tolerance)

**Cannot Exist Without:**
- Concurrent execution is **impossible** without async I/O
- Lock-free writes are **automatic** with AsyncSqliteSaver
- Production concurrency is **blocked** until this migration

---

## Code Pattern

```python
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
from langgraph.graph import StateGraph, START, END
import asyncio

# Setup async checkpointer
async def setup_graph():
    async with AsyncSqliteSaver.from_conn_string("checkpoints.sqlite") as checkpointer:
        await checkpointer.setup()

        # Build graph
        builder = StateGraph(State)
        builder.add_node("process", process_node)
        builder.add_edge(START, "process")
        builder.add_edge("process", END)

        graph = builder.compile(checkpointer=checkpointer)

        # Concurrent execution test
        configs = [
            {"configurable": {"thread_id": f"user-{i}"}}
            for i in range(10)
        ]

        # Launch 10 concurrent invocations
        results = await asyncio.gather(*[
            graph.ainvoke({"message": f"Request {i}"}, config)
            for i, config in enumerate(configs)
        ])

        print(f"Completed {len(results)} concurrent invocations")
        return results

# Run test
results = asyncio.run(setup_graph())
```

---

## Execution Protocol

**Prerequisites:**
- M1 complete (all 4 emergent features witnessed)
- Python async/await understanding
- AsyncSqliteSaver available in langgraph

**Execution Steps:**
1. Replace `SqliteSaver` import with `AsyncSqliteSaver` from `langgraph.checkpoint.sqlite.aio`
2. Wrap checkpointer setup in `async with` context manager
3. Use `await checkpointer.setup()` instead of `checkpointer.setup()`
4. Replace all `graph.invoke()` calls with `await graph.ainvoke()`
5. Test concurrent execution with `asyncio.gather()`
6. Verify zero database lock errors

**Verification Steps:**
1. Run 10 concurrent invocations using `asyncio.gather()`
2. Monitor logs for "database locked" errors (should be zero)
3. Verify all 10 invocations complete successfully
4. Check execution time - concurrent should be ~same as single (not 10x)
5. Test M1 features still work (session memory, time travel, HITL, fault tolerance)

---

## The Completion Signal

**Signal:** 10 concurrent invocations without locks

**Evidence Required:**
- Terminal output showing 10 concurrent invocations launched
- Terminal output showing all 10 completing successfully
- Log file showing zero "database locked" errors
- Execution time showing concurrent performance (not sequential)
- Verification that M1 emergent features still work with async

**State Transition:**
```yaml
before:
  status: complete
  witness: impossible (concurrent invocations cause locks)
  concurrency: blocked (sync I/O only)
  max_throughput: 1 req/sec

after:
  status: complete
  witness: observed (10 concurrent invocations, zero lock errors)
  concurrency: unlocked (async I/O)
  max_throughput: 10+ req/sec
  evidence: [concurrent execution log, zero errors, performance metrics]
```

---

## Constraint Compliance

**CONTEXT_PRESERVATION:** Async migration preserves thread_id continuity - concurrent invocations with different thread_ids maintain isolated contexts

**CONSTRAINT_INHERITANCE:** Async children inherit async constraints - if parent uses AsyncSqliteSaver, all spawned agents must use async patterns

**TRACE_REQUIRED:** Every async invocation traced independently - concurrent executions have separate trace IDs in Langfuse

**RESOURCE_STEWARDSHIP:** Async I/O reduces resource waste - threads don't block waiting for I/O, enabling higher concurrency with same resources

**RESIDUE_FREE:** Async cleanup is automatic - context manager ensures connections close properly, no leaked async resources

---

## Notes

**Critical Insight:** AsyncSqliteSaver uses WAL mode's concurrent read capability. Multiple readers can access checkpoints while one writer updates. This removes the "database locked" bottleneck.

**Async Pattern Migration:**
```python
# Before (sync)
result = graph.invoke(input, config)

# After (async)
result = await graph.ainvoke(input, config)
```

**Concurrency vs Parallelism:**
- Concurrency: 10 invocations interleaved (async I/O)
- Parallelism: 10 invocations on separate cores (requires multiprocessing)
- AsyncSqliteSaver enables concurrency, not true parallelism

**Performance Expectation:**
- Sequential: 10 invocations Ã— 1 second each = 10 seconds total
- Concurrent: 10 invocations overlapped = ~1-2 seconds total
- If concurrent time is still 10 seconds, async migration failed

**M1 Feature Compatibility:**
All M1 emergent features work identically with async:
- Session Memory: `await graph.ainvoke()` with same thread_id
- Time Travel: Load checkpoint_id in async config
- HITL: `await graph.get_state()`, `await graph.update_state()`, `await graph.ainvoke(None)`
- Fault Tolerance: `await graph.ainvoke(None)` resumes from checkpoint
