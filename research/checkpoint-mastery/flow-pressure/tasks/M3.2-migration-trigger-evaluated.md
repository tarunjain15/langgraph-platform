```yaml
task_id: M3.2
phase: M3
type: Decision
status: pending
created: 2025-11-17
```

# Task 3.2: [Decision] Migration Trigger Evaluated

## The Constraint

**Before:** No decision framework for when to migrate → delay until crisis → reactive scaling
**After:** Decision matrix shows "MIGRATE NOW" based on objective metrics → proactive scaling

---

## The Witness

**Observable Truth:** Decision matrix evaluation returns "MIGRATE NOW - Write errors >1% (SQLite saturated)" when metrics exceed threshold

**Why This Witness:**
- Automated decision recommendation based on metrics can ONLY exist if decision logic was implemented
- The ability to know "MIGRATE NOW" vs "SQLite sufficient" before crisis is **impossible** without threshold evaluation
- Decision logged with justification proves audit trail exists
- This witness is **measurable** (decision output) and **automatic** (evaluates continuously)

---

## Acceptance Criteria

**Must Verify:**
- [ ] Decision function implemented with 4 trigger conditions
- [ ] Trigger 1: Error rate >1% → "MIGRATE NOW" (SQLite saturated)
- [ ] Trigger 2: Writes >100/sec sustained → "MIGRATE NOW" (capacity ceiling)
- [ ] Trigger 3: Multi-server deployment → "MIGRATE NOW" (network DB required)
- [ ] Trigger 4: File size >5GB → "MIGRATE SOON" (performance degradation)
- [ ] Decision logged with timestamp, metrics, and justification
- [ ] Safe state: Error rate <1%, writes <80/sec → "SQLite sufficient"

**Cannot Exist Without:**
- Automated decision recommendation is **impossible** without decision logic
- Justification with metrics is **automatic** once evaluation implemented
- Logged decisions are **measurable** proof of evaluation working

---

## Code Pattern

```python
from dataclasses import dataclass
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

@dataclass
class MigrationMetrics:
    """Metrics used for migration decision."""
    error_rate: float  # Percentage (0-100)
    writes_per_second: float  # Current throughput
    deployment: str  # "single-server" or "multi-server"
    file_size_gb: float  # SQLite file size in GB
    timestamp: datetime

@dataclass
class MigrationDecision:
    """Migration decision with justification."""
    decision: str  # "MIGRATE NOW", "MIGRATE SOON", "SQLite sufficient"
    justification: str
    metrics: MigrationMetrics
    timestamp: datetime

def should_migrate_to_postgresql(metrics: MigrationMetrics) -> MigrationDecision:
    """Evaluate migration decision based on metrics."""

    timestamp = datetime.now()

    # Trigger 1: Error rate >1%
    if metrics.error_rate > 1.0:
        decision = MigrationDecision(
            decision="MIGRATE NOW",
            justification=f"Write errors >1% ({metrics.error_rate:.2f}%) - SQLite saturated",
            metrics=metrics,
            timestamp=timestamp
        )
        logger.warning(f"Migration decision: {decision.decision} - {decision.justification}")
        return decision

    # Trigger 2: Throughput >100/sec
    if metrics.writes_per_second > 100:
        decision = MigrationDecision(
            decision="MIGRATE NOW",
            justification=f"Throughput >100/sec ({metrics.writes_per_second:.1f}/sec) - capacity ceiling reached",
            metrics=metrics,
            timestamp=timestamp
        )
        logger.warning(f"Migration decision: {decision.decision} - {decision.justification}")
        return decision

    # Trigger 3: Multi-server deployment
    if metrics.deployment == "multi-server":
        decision = MigrationDecision(
            decision="MIGRATE NOW",
            justification="Multi-server deployment requires network-accessible database",
            metrics=metrics,
            timestamp=timestamp
        )
        logger.warning(f"Migration decision: {decision.decision} - {decision.justification}")
        return decision

    # Trigger 4: File size >5GB
    if metrics.file_size_gb > 5.0:
        decision = MigrationDecision(
            decision="MIGRATE SOON",
            justification=f"SQLite file size >5GB ({metrics.file_size_gb:.2f}GB) - performance degradation likely",
            metrics=metrics,
            timestamp=timestamp
        )
        logger.info(f"Migration decision: {decision.decision} - {decision.justification}")
        return decision

    # All checks passed - SQLite sufficient
    decision = MigrationDecision(
        decision="SQLite sufficient",
        justification=f"All metrics within acceptable range (error rate: {metrics.error_rate:.2f}%, throughput: {metrics.writes_per_second:.1f}/sec, file size: {metrics.file_size_gb:.2f}GB)",
        metrics=metrics,
        timestamp=timestamp
    )
    logger.info(f"Migration decision: {decision.decision}")
    return decision

# Usage with M3.1 metrics
from prometheus_api_client import PrometheusConnect

prom = PrometheusConnect(url="http://localhost:9090")

# Collect current metrics
error_rate_query = 'rate(checkpoint_writes_total{status="error"}[5m]) / rate(checkpoint_writes_total[5m]) * 100'
throughput_query = 'rate(checkpoint_writes_total[1m])'

error_rate = prom.custom_query(error_rate_query)[0]['value'][1]
throughput = prom.custom_query(throughput_query)[0]['value'][1]
file_size_gb = os.path.getsize("checkpoints.sqlite") / (1024 ** 3)

metrics = MigrationMetrics(
    error_rate=float(error_rate),
    writes_per_second=float(throughput),
    deployment="single-server",  # or detect from config
    file_size_gb=file_size_gb,
    timestamp=datetime.now()
)

# Evaluate decision
decision = should_migrate_to_postgresql(metrics)
print(f"Decision: {decision.decision}")
print(f"Justification: {decision.justification}")

# Log to decision history (for audit trail)
with open("migration_decisions.jsonl", "a") as f:
    f.write(decision.model_dump_json() + "\n")
```

---

## Execution Protocol

**Prerequisites:**
- M3.1 complete (Metrics collection working)
- Prometheus/CloudWatch API access
- Decision log file/database configured

**Execution Steps:**
1. Implement `should_migrate_to_postgresql()` function
2. Test with safe metrics (error_rate=0.1%, writes=50/sec)
   - Expected: "SQLite sufficient"
3. Test with trigger 1 (error_rate=1.5%)
   - Expected: "MIGRATE NOW - Write errors >1%"
4. Test with trigger 2 (writes=120/sec)
   - Expected: "MIGRATE NOW - Throughput >100/sec"
5. Test with trigger 3 (deployment="multi-server")
   - Expected: "MIGRATE NOW - Multi-server requires network DB"
6. Test with trigger 4 (file_size=5.5GB)
   - Expected: "MIGRATE SOON - File size >5GB"
7. Verify decisions logged with justification

**Verification Steps:**
1. Run decision function with current metrics
2. Verify correct decision based on thresholds
3. Check decision log: `tail -n 10 migration_decisions.jsonl`
4. Verify log contains: decision, justification, metrics, timestamp
5. Test all 4 trigger conditions
6. Test safe condition (no triggers)
7. Verify audit trail complete

---

## The Completion Signal

**Signal:** Decision matrix working, all triggers tested, decisions logged

**Evidence Required:**
- Test results for all 5 conditions (4 triggers + 1 safe)
- Decision log showing justifications
- Function code demonstrating threshold logic
- Integration with M3.1 metrics verified
- Audit trail complete (all decisions logged)

**State Transition:**
```yaml
before:
  status: pending
  witness: impossible (no decision framework)
  migration_timing: reactive (crisis-driven)
  justification: ad-hoc

after:
  status: complete
  witness: observed (decision matrix working)
  migration_timing: proactive (metric-driven)
  justification: logged with metrics
  evidence: [test_results, decision_log, metric_integration]
```

---

## Constraint Compliance

**CONTEXT_PRESERVATION:** Decision history preserved in log - understand why migration decisions were made over time. Historical context enables learning.

**CONSTRAINT_INHERITANCE:** Decision logic inherited by future scaling decisions - same threshold framework applies to PostgreSQL → distributed DB migration.

**TRACE_REQUIRED:** Every decision traceable with metrics and justification - full audit trail of scaling decisions. No mystery migrations.

**RESOURCE_STEWARDSHIP:** Decision framework prevents premature optimization - only migrate when metrics justify it. Minimal necessary infrastructure.

**RESIDUE_FREE:** Decisions logged cleanly with structured data - no ad-hoc spreadsheets or tribal knowledge. Clean decision record.

---

## Notes

**Critical Insight:** This task removes the constraint of "guessing when to migrate". Metric-based decision → objective trigger → proactive scaling → no crisis.

**Why These Thresholds:**
- **Error rate >1%:** Indicates SQLite saturation, write conflicts increasing
- **Throughput >100/sec:** SQLite ceiling reached, further growth impossible
- **Multi-server:** File-based storage doesn't support network access
- **File size >5GB:** Query performance degradation, backup/restore slow

**Decision vs Action:** This task decides WHEN to migrate, not HOW. M4 implements the migration itself.

**Continuous Evaluation:** Run decision function daily (via cron) to monitor trigger conditions. Early warning of migration need.

**False Triggers:** Temporary spikes (30 seconds at 150/sec) shouldn't trigger migration. Use 5-minute sustained thresholds.

**Testing Gotcha:** Don't test with production data - use staging environment with synthetic load to verify trigger conditions.

**Alert Integration:** Connect decision function to M3.1 alerts - when alert fires, decision function explains what to do.

**Migration Timeline:** "MIGRATE NOW" = start within 1 week. "MIGRATE SOON" = plan within 1 month. "SQLite sufficient" = no action needed.
